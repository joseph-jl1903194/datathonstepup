{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newshack_kaggle2 (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.5",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "id": "_2qxcnWknnpk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import the necessary libraries"
      ]
    },
    {
      "metadata": {
        "_uuid": "d6fb32fd69316596e236eab5fb8cf77c848508c3",
        "id": "CkKZaRnDnnqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7e7d23d-7940-40c1-cdc2-71c4452371d0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.models import LdaModel\n",
        "from gensim import models, corpora, similarities\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import time\n",
        "from nltk import FreqDist\n",
        "from scipy.stats import entropy\n",
        "from subprocess import check_output\n",
        "import io\n",
        "import matplotlib\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "sns.set_style(\"darkgrid\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "omw7cbMf8RAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8e61932e-54ee-4f35-ecac-2318d511338c"
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-27 06:26:54--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  47.3MB/s    in 30s     \n",
            "\n",
            "2019-01-27 06:27:24 (48.8 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dzUGlyPmnnqw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "f = io.open(\"task1.train.txt\", mode=\"r\", encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDUHwnyRnnrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=[\"text\",\"article_id\",\"propaganda\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AZVFXRmPnnrw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines = f.read().split(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEP2R8pxnnr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = []\n",
        "for i in lines:\n",
        "    i = i.split(\"\\t\")\n",
        "    x.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h1DVo8osnnsM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(x, columns=[\"text\",\"article_id\",\"propaganda\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNoXdLg4nnsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "59d5ab39-fba4-4397-b628-578595422b1e"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>article_id</th>\n",
              "      <th>propaganda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Et tu, Rhody?  A recent editorial in the Provi...</td>\n",
              "      <td>727600136</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A recent post in The Farmington Mirror — our t...</td>\n",
              "      <td>731714618</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>President Donald Trump, as he often does while...</td>\n",
              "      <td>731714635</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>February is Black History Month, and nothing l...</td>\n",
              "      <td>728627182</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The snow was so heavy, whipped up by gusting w...</td>\n",
              "      <td>728627443</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text article_id  \\\n",
              "0  Et tu, Rhody?  A recent editorial in the Provi...  727600136   \n",
              "1  A recent post in The Farmington Mirror — our t...  731714618   \n",
              "2  President Donald Trump, as he often does while...  731714635   \n",
              "3  February is Black History Month, and nothing l...  728627182   \n",
              "4  The snow was so heavy, whipped up by gusting w...  728627443   \n",
              "\n",
              "       propaganda  \n",
              "0  non-propaganda  \n",
              "1  non-propaganda  \n",
              "2  non-propaganda  \n",
              "3  non-propaganda  \n",
              "4  non-propaganda  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "8K9V8Zoknnsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b2814bd9-1a9f-4791-f4f7-32c2130dbd1d"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "vJA6L8lZnnss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "# MY STOPWORDS\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\", \"no\", \"nor\",\"not\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqpVFOmknns0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adb51381-c39c-40cc-987a-af3bcfcc7fb3"
      },
      "cell_type": "code",
      "source": [
        "# Combining all the above stundents \n",
        "from tqdm import tqdm\n",
        "preprocessed_text = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(df['text'].values):\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    #sentance = decontracted(sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "    preprocessed_text.append(sentance.strip())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35994/35994 [00:46<00:00, 774.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kVRBZgOunntC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"text\"] = preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f674695f1742479cefdeec0e81ab469f7b6ec90f",
        "id": "4G5fUYy6nntr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the data into Pandas dataframe"
      ]
    },
    {
      "metadata": {
        "id": "CD9w5y2Tnntu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1516ee35-1584-4923-cc9d-18b50e6fd908"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>article_id</th>\n",
              "      <th>propaganda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>et tu rhody recent editorial providence journa...</td>\n",
              "      <td>727600136</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recent post farmington mirror town version oni...</td>\n",
              "      <td>731714618</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>president donald trump often responding natura...</td>\n",
              "      <td>731714635</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>february black history month nothing looms lar...</td>\n",
              "      <td>728627182</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>snow heavy whipped gusting winds travel nearly...</td>\n",
              "      <td>728627443</td>\n",
              "      <td>non-propaganda</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text article_id  \\\n",
              "0  et tu rhody recent editorial providence journa...  727600136   \n",
              "1  recent post farmington mirror town version oni...  731714618   \n",
              "2  president donald trump often responding natura...  731714635   \n",
              "3  february black history month nothing looms lar...  728627182   \n",
              "4  snow heavy whipped gusting winds travel nearly...  728627443   \n",
              "\n",
              "       propaganda  \n",
              "0  non-propaganda  \n",
              "1  non-propaganda  \n",
              "2  non-propaganda  \n",
              "3  non-propaganda  \n",
              "4  non-propaganda  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "53083ccecf39523cff290495a6cc768061ba9b46",
        "id": "8-NTftxtnnt5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Drop the columns that are not required for the neural network."
      ]
    },
    {
      "metadata": {
        "_uuid": "3c7060084470000f39a2dcc15b656586dcd6e9fd",
        "id": "VfHMbl_ennt9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Understand the distribution better."
      ]
    },
    {
      "metadata": {
        "_uuid": "a12002f521dd8eaeb0f69a932cbf23815ffd09d7",
        "id": "Hw39hpLWnnuA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "ba1c8d41-8d3a-4f6a-e17f-5fb5ffe89976"
      },
      "cell_type": "code",
      "source": [
        "sns.countplot(df.propaganda)\n",
        "plt.xlabel('propaganda')\n",
        "plt.title('Number of prp and nonprop news')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Number of prp and nonprop news')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJRneAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-yTPFyCVnnuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TS5Wu0NJAZoY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "353a8191f86c3a22843a729b5d4a5acefbf94be8",
        "id": "XJRVDvqjnnuX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Create input and output vectors.\n",
        "* Process the labels."
      ]
    },
    {
      "metadata": {
        "id": "kMTLEZPOnnua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['length'] = [len(text) for text in df['text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y7YMjFtNAdx2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df[df.length < 40000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Jt6Y0vgnnuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "065d2ebc-3e4d-4fcc-bfd8-0d4d5653882c"
      },
      "cell_type": "code",
      "source": [
        "df['length'].describe()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    35990.000000\n",
              "mean      2454.467519\n",
              "std       1992.363184\n",
              "min         23.000000\n",
              "25%       1197.000000\n",
              "50%       1977.000000\n",
              "75%       3189.000000\n",
              "max      34137.000000\n",
              "Name: length, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a1a345c1683e2fcc7173ecae867a5da87f2dde24",
        "id": "uw6-1ANTnnuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df.text\n",
        "Y = df.propaganda\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "Y = Y.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "150e244a39b814d8a41bbe0e419bc5f28e457dd6",
        "id": "J0tijwO2nnu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split into training and test data."
      ]
    },
    {
      "metadata": {
        "_uuid": "aa3386af09469682c66cc53a1830a4e42f0e70b6",
        "scrolled": true,
        "id": "0_CebE0-nnu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMXJ0hpVnnu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Embedding(vocab_size ,300,input_length=120)(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c5378d55c271e01480c1ac07f94ff99a80f900d6",
        "id": "vy1nDkXbnnvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Process the data\n",
        "* Tokenize the data and convert the text to sequences.\n",
        "* Add padding to ensure that all the sequences have the same shape.\n",
        "* There are many ways of taking the *max_len* and here an arbitrary length of 150 is chosen."
      ]
    },
    {
      "metadata": {
        "_uuid": "bdca14f2b8cd7bd7cb5ee66fd40ea522217c03c6",
        "id": "pIPQxHULnnvF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_words = 100000 \n",
        "max_len = 500\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIY7nb9mnnvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Facebook Fasttext embedding"
      ]
    },
    {
      "metadata": {
        "id": "a0sBBklnnnvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import os\n",
        "\n",
        "\n",
        "class EmbedLoader:\n",
        "    \"\"\"\n",
        "    @author: Ahmad Barqawi\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_embedding(self, embedding_file, embed_size):\n",
        "        embedding_index = {}\n",
        "        with open(embedding_file, encoding='utf8') as f:\n",
        "            for line in f:\n",
        "                values = line.rstrip().rsplit(' ')\n",
        "                # word = ' '.join(values[:-embed_size])\n",
        "                # coefs = np.asarray(values[-embed_size:], dtype='float32')\n",
        "                word = values[0]\n",
        "                coefs = np.asarray(values[1:], dtype='float32')\n",
        "                embedding_index[word] = coefs\n",
        "        f.close()\n",
        "\n",
        "        return embedding_index\n",
        "\n",
        "    def get_embedding2(self, embedding_file):\n",
        "        embeddings_index = dict(self._get_coefs(*o.rstrip().split(' ')) for o in open(embedding_file))\n",
        "        return embeddings_index\n",
        "\n",
        "    def _get_coefs(self,word, *arr):\n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    def get_embedding_matrix(self, embedding_index, word_index, embed_size, max_features):\n",
        "\n",
        "        print(\"size word index: \" , len(word_index))\n",
        "        vocab_size = min(len(word_index), max_features) + 1\n",
        "        embedding_matrix = np.zeros((vocab_size, embed_size))\n",
        "\n",
        "        print(\"embedding_matrix shape: \", embedding_matrix.shape)\n",
        "\n",
        "        for word, index in word_index.items():\n",
        "            if index >= vocab_size:\n",
        "                continue\n",
        "            embedding_vector = embedding_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[index] = embedding_vector\n",
        "\n",
        "        return embedding_matrix, vocab_size\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gIvp8L0J3kJJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('crawl-300d-2M.vec.zip', 'r') as zip:\n",
        "  zip.extract('crawl-300d-2M.vec')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xNQs5Ho0nnvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f967ea4b-ef10-4c84-bd95-fdc073886616"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "embed_loader = EmbedLoader()\n",
        "embedding_index = embed_loader.get_embedding2('crawl-300d-2M.vec')\n",
        "embedding_matrix, vocab_size = embed_loader.get_embedding_matrix(embedding_index, tok.word_index,300, max_words)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size word index:  150018\n",
            "embedding_matrix shape:  (100001, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ad8706caa7a447fb49b44919fd109129e4082a93",
        "id": "-GZk7ZQnnnv3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN\n",
        "Define the RNN structure."
      ]
    },
    {
      "metadata": {
        "_uuid": "78fff25b8be1de575bff071a2027f3dd2b11b911",
        "id": "4ANLzx67nnv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    embed_size = 300\n",
        "    emb_layer = Embedding(vocab_size, embed_size, weights=[embedding_matrix], trainable=False, name='embedding_1')(inputs)\n",
        "    layer = emb_layer\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dw8Blah3nnv_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d7c489e32bff6d12b8c08c07a91e9ba5d302e0e",
        "id": "cpWni9_SnnwF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Call the function and compile the model."
      ]
    },
    {
      "metadata": {
        "_uuid": "a0ede32d4127e8b4990fd74fe97fadef9e565d17",
        "id": "hICeDH_TnnwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "097419d1-2f6c-41a9-b334-92263bacd950"
      },
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 500, 300)          30000300  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 30,110,637\n",
            "Trainable params: 110,337\n",
            "Non-trainable params: 30,000,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "bc2e0a3ec50d14c790b82d66f9255456ec6a69da",
        "id": "l9PW-SYDnnwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit on the training data."
      ]
    },
    {
      "metadata": {
        "id": "Wix4zXANDGdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dR2v5sy-gEH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=2,\n",
        "                          verbose=2, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='model_check.hdf5', verbose=1, monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "98f6d6318352420ea49c532cda158f715f940f4b",
        "id": "DBijyx2YnnwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "a988ded0-123e-425a-8f8a-1559eb9cb916"
      },
      "cell_type": "code",
      "source": [
        "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2,callbacks=[early_stopping, checkpointer ])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24472 samples, validate on 6119 samples\n",
            "Epoch 1/10\n",
            "24472/24472 [==============================] - 309s 13ms/step - loss: 0.2561 - acc: 0.9096 - val_loss: 0.1916 - val_acc: 0.9294\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.19160, saving model to model_check.hdf5\n",
            "Epoch 2/10\n",
            "24472/24472 [==============================] - 307s 13ms/step - loss: 0.1763 - acc: 0.9333 - val_loss: 0.1842 - val_acc: 0.9240\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.19160 to 0.18420, saving model to model_check.hdf5\n",
            "Epoch 3/10\n",
            "24472/24472 [==============================] - 308s 13ms/step - loss: 0.1487 - acc: 0.9436 - val_loss: 0.1650 - val_acc: 0.9415\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.18420 to 0.16502, saving model to model_check.hdf5\n",
            "Epoch 4/10\n",
            "24472/24472 [==============================] - 307s 13ms/step - loss: 0.1311 - acc: 0.9515 - val_loss: 0.1647 - val_acc: 0.9448\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.16502 to 0.16465, saving model to model_check.hdf5\n",
            "Epoch 5/10\n",
            "24472/24472 [==============================] - 307s 13ms/step - loss: 0.1551 - acc: 0.9402 - val_loss: 0.1830 - val_acc: 0.9279\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.16465\n",
            "Epoch 6/10\n",
            "24472/24472 [==============================] - 307s 13ms/step - loss: 0.1348 - acc: 0.9506 - val_loss: 0.1559 - val_acc: 0.9456\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.16465 to 0.15590, saving model to model_check.hdf5\n",
            "Epoch 7/10\n",
            "24472/24472 [==============================] - 307s 13ms/step - loss: 0.1184 - acc: 0.9570 - val_loss: 0.1848 - val_acc: 0.9439\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.15590\n",
            "Epoch 8/10\n",
            "24472/24472 [==============================] - 307s 13ms/step - loss: 0.1203 - acc: 0.9546 - val_loss: 0.1609 - val_acc: 0.9428\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.15590\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb49cc842b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "2XjtCg53GDPb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load best score\n",
        "model.load_weights('model_check.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "448ab38c2f804e47df48eb45385393aaec168032",
        "id": "VXfEEfPZnnwc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model performs well on the validation set and this configuration is chosen as the final model."
      ]
    },
    {
      "metadata": {
        "_uuid": "ccca7839445a7d663ee7bc425a16e247df3e0e5b",
        "id": "0e79nmGWnnwf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Process the test set data."
      ]
    },
    {
      "metadata": {
        "_uuid": "80036135a11387d952becaf2fecf653a65c02328",
        "id": "LmwjVX1vnnwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0b60d7d2bcc0aabf77c8c8766c59f8d73cd34547",
        "id": "mKGilUg7nnwv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test set."
      ]
    },
    {
      "metadata": {
        "_uuid": "0db183049b59d96388812a98efedfc865b7cc141",
        "id": "2eBCkD9Vnnw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f1c826a-8490-4277-afc1-522b84bac733"
      },
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(test_sequences_matrix,Y_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5399/5399 [==============================] - 34s 6ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tS2bFMdOnnxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6a7f61f-a8f7-4448-bb4c-2bad076c9bf2"
      },
      "cell_type": "code",
      "source": [
        "accr"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1616873948245407, 0.9398036673899646]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "qJmKhXfEnnxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_sequences_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GXvpAkQunnxb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] < 0.4:\n",
        "        y_pred[i] = 0\n",
        "    else:\n",
        "        y_pred[i] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MEroJPhnnxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9dbcd56-5f32-4bed-cca4-e9152591aade"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, fbeta_score\n",
        "f1_score(Y_test, y_pred, average='macro')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8425999471935577"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "Tk4jXYTAnnxo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7trzm7wynnxu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q39iug-snnxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = get_file('task1.train.txt')\n",
        "df2 = pd.DataFrame(columns=[\"text\",\"article_id\",\"propaganda\"])\n",
        "lines = load_text_lines(filename)\n",
        "lines = lines.split(\"\\n\")\n",
        "x = []\n",
        "for i in lines:\n",
        "    i = i.split(\"\\t\")\n",
        "    x.append(i)\n",
        "df2 = pd.DataFrame(x, columns=[\"text\",\"article_id\",\"propaganda\"])\n",
        "df2.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rBVDSAMSnnx0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2.propaganda.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fXUHis96nnx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2['propaganda'] = df2['propaganda'].map({'propaganda': 1, 'non-propaganda': 0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rWXOOmoFnnyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counts = df2.propaganda.value_counts()\n",
        "counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uT6NHL5SnnyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2 = df2.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDkrjyM3nnyJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is a highly skewed dataset. There are only 4021 \n",
        "print(\"Number of Propaganda items\", counts[1])\n",
        "print(\"Number of Not Propaganda items\", counts[0])\n",
        "print(\"Total number of records\", len(df2))\n",
        "percentage = (counts[1]*100)/len(df2)\n",
        "\n",
        "print(\"percentage of propaganda items {0:.2f}%\".format(percentage))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EdjPc2dmnnyM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values = df2['propaganda'].value_counts().keys().tolist()\n",
        "counts = df2['propaganda'].value_counts().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7aEwMQSBnnyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tt4M1ptInnyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#NLTK STOPWORDS\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "# MY STOPWORDS\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\", \"no\", \"nor\",\"not\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2UPFD6jXnnyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Combining all the above stundents \n",
        "from tqdm import tqdm\n",
        "preprocessed_text = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(df2['text'].values):\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    sentance = decontracted(sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "    preprocessed_text.append(sentance.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WE1WtHmjnnyg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df2[\"Cleaned_Text\"] = preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ch7rtLlInnyl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final = df2\n",
        "final.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HEOPLgtnnyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "restart_here = final.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55ONz_dxnnyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final = restart_here\n",
        "\n",
        "# Splitting the dataset into Train, Test.\n",
        "# Let's go for an 80 - 20 split.\n",
        "labels = final[\"propaganda\"]\n",
        "finals = final.drop(columns=[\"propaganda\"], axis=1, inplace=False)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(finals, labels, test_size=0.15, random_state=42)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4D0MOOLnnyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1wv50Keynny3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BoW\n",
        "count_vect = CountVectorizer() #in scikit-learn\n",
        "count_vect.fit(preprocessed_text)\n",
        "print(\"some feature names \", count_vect.get_feature_names()[:10])\n",
        "print('='*50)\n",
        "\n",
        "final_counts = count_vect.transform(preprocessed_text)\n",
        "print(\"the type of count vectorizer \",type(final_counts))\n",
        "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
        "print(\"the number of unique words \", final_counts.get_shape()[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oVi74ZPLnny6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntyZcwbInny8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please write all the code with proper documentation\n",
        "def bag_of_words(train_data, test_data, validation_data = None):\n",
        "    count_vect = CountVectorizer() #in scikit-learn\n",
        "    count_vect.fit(train_data)\n",
        "    print(\"some feature names \", count_vect.get_feature_names()[:10])\n",
        "    print('='*50)\n",
        "    train_data_vectorized = count_vect.transform(train_data)\n",
        "    test_data_vectorized = count_vect.transform(test_data)\n",
        "    if validation_data:\n",
        "        validation_data_vectorized = count_vect.tranform(validation_data)\n",
        "    else:\n",
        "        validation_data_vectorized = None\n",
        "    print(\"the type of count vectorizer \",type(train_data_vectorized))\n",
        "    print(\"the shape of out text BOW vectorizer \",train_data_vectorized.get_shape())\n",
        "    print(\"the number of unique words \", train_data_vectorized.get_shape()[1])\n",
        "    return train_data_vectorized, test_data_vectorized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ypFwRD9fnny-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_vectorized , test_data_vectorized = bag_of_words(X_train[\"Cleaned_Text\"], X_test[\"Cleaned_Text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6-aBUzGnnzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_vectorized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lvSO_Q5PnnzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#knn = KNeighborsClassifier()\n",
        "#n_list = range(1,10,2)\n",
        "#parameters = {\"n_neighbors\":n_list}\n",
        "#clf = GridSearchCV(knn, parameters, cv=3, verbose=2, n_jobs=2)\n",
        "#clf.fit(train_data_vectorized,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPMzAxtinnzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A6DdpKunnnzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
        "clf2.fit(train_data_vectorized,y_train)\n",
        "clf2.score(test_data_vectorized,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "blDZ4XxjnnzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_2 = clf2.predict(test_data_vectorized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OrgLdUJJnnzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_true = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFyH3zwfnnzT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(f1_score(y_true, y_pred_2))\n",
        "print(recall_score(y_true, y_pred_2))\n",
        "print(precision_score(y_true, y_pred_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Fa4Eie4nnza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(train_data_vectorized,y_train)\n",
        "mnb_pred = mnb.predict(test_data_vectorized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lzo7kc86nnze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(f1_score(y_true, mnb_pred))\n",
        "print(recall_score(y_true, mnb_pred))\n",
        "print(precision_score(y_true, mnb_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWiEh2sgnnzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnb_pred , y_pred_2 , y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K320DIA9nnzi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(sequences_matrix_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JH5y2f7nnzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#y_avg = [(x + y + z) / 3 for x in y_pred for y in y_pred_2 for z in mnb_pred]\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] < 0.4:\n",
        "        y_pred[i] = 0\n",
        "    else:\n",
        "        y_pred[i] = 1\n",
        "        \n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ye6Eybmannzo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(y_pred))\n",
        "print(len(mnb_pred))\n",
        "print(len(y_pred_2))\n",
        "#for i in range(len(y_pred))\n",
        "\n",
        "\n",
        "#y_avg = np.zeros(len(y_pred))\n",
        "#for i in range(len(y_pred)):\n",
        "#    y_avg[i] = (y_pred[i] + y_pred_2[i] + mnb_pred[i]) / 3\n",
        "#    #y_avg.append(avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwKpitxXnnzr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#y_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C0Lh15e1nnzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGX5mqrPnnzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(y_avg)):\n",
        "    if y_avg[i] < 0.4:\n",
        "        y_avg[i] = 0\n",
        "    else:\n",
        "        y_avg[i] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7JI_2-FJnnz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-5MqKV4gnnz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(y_avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZIcFp-c7nnz8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}